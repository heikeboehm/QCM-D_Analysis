{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36cb9459-f1c1-499a-b654-9c0f084596e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Program Description:\n",
    "This program processes QCM-D data recorded on a QSense-Analyzer using Q-Tools Software (Version 2.8.5) \n",
    "and flow modules. It breaks down the data into independent, unified datasets for each sensor position.\n",
    "\n",
    "Lag time between start of tubing to crystal (needs to be adjusted if different tube set used - see cell No. 4)\n",
    "(Experimental note: all tubes are labeled to ensure the same tubes are used with the same sensors each time)\n",
    "S1: 135 sek at 50µl/min\n",
    "S2: 140 sek at 50µl/min\n",
    "S3: 140 sek at 50µl/min\n",
    "S4: 145 sek at 50µl/min\n",
    "\n",
    "Author:\n",
    "- Heike Böhm, Department of Cellular Biophysics, MPI for Medical Research (MPImF-CBP-GS)\n",
    "\n",
    "Input Data Sources:\n",
    "- Rawdata as a tab-spaced CSV file exported from Q-Tools using \",\" as decimal points\n",
    "  (expects data to be saved with 'Data_ID_rawdata.txt' format)\n",
    "- Corresponding timeline copied and pasted from the notes window of Q-Tools into a plain text file\n",
    "  (expects data to be saved with 'Data_ID_timeline.txt' format)\n",
    "  Format: h:mm:ss S# flow_speed description. (Where S# corresponds to the sensor and its respective number)\n",
    "\n",
    "Output Generated:\n",
    "- CSV-Files saving:\n",
    "    - adj_qcmd_data: \n",
    "        Adjusted QCM-D dataset with time in seconds adjusted with resp. lag time, normalized Δf/n, and normalized D for all overtones. \n",
    "        Normalization is achieved by subtracting the averaged value of the first 100 data points \n",
    "        for each measured frequency and dissipation overtone.\n",
    "        All normalized frequency values have been divided by the overtone number to represent Δf/n.\n",
    "    - adj_timeline_data: \n",
    "        Timeline given in the text file for the respective sensor, including the time in seconds, \n",
    "        the flow speed in µm/min, and information on the solution change.\n",
    "\n",
    "Comments on Coding:\n",
    "- For all variables lower_case_with_underscores are used. \n",
    "- CapWords are used for class names \n",
    "- UPPER_CASE_WITH_UNDERSCORES are used for constants.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355bb01d-5d00-4490-b1d7-e89d90c8eb47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eccbaaa31034477b39e780254cfcb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='/Users/hboehm/Seafile/LEAF/QCMD/QCMD_data/Inbox', description='Path to QCMD flow ra…"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Enter the path to the folder in which the QCMD flow rawdata is saved\n",
    "'''\n",
    "\n",
    "input_widget_width = '1000px'\n",
    "description_width = '300px'\n",
    "\n",
    "path_widget = widgets.Text(\n",
    "    value=\"Inbox\",\n",
    "    description=\"Path to QCMD flow rawdata:\"\n",
    ")\n",
    "\n",
    "path = None\n",
    "\n",
    "path_widget.layout.width = input_widget_width\n",
    "path_widget.style.description_width = description_width\n",
    "\n",
    "def save_path(sender):\n",
    "    global path \n",
    "    path = path_widget.value\n",
    "\n",
    "save_button = widgets.Button(description=\"Save\")\n",
    "save_button.on_click(save_path)\n",
    "\n",
    "widgets.VBox([path_widget, save_button])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceaad37a-9883-4a64-8cad-a26ba6645b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "- Reads in the rawdata txt File with time in seconds as the index.\n",
    "\n",
    "Output:\n",
    "- persistentID: represents the uniqueID of the dataset - extracted from the name of the rawdata title \n",
    "- sensors: number of sensors for which data is available\n",
    "- adj_qcmd_data as long format pandas dataframe\n",
    "    - frequency and Dissipation values are normalized to start at zero by subtracting the averaged value of the first 100 data points.\n",
    "    - frequency values are divided by the overtone number to represent Δf/n.\n",
    "\n",
    "Note on Coding:\n",
    "- The rawdata is expected to be exported with column titles in the format\"Time_S\" and \"Mn_S [unit]\"\n",
    "    where M represents f for frequency or D for dissipation; n is the overtone number and S the sensor No.\n",
    "\"\"\"\n",
    "\n",
    "def process_rawdata(file_path):\n",
    "    qcmd_data_wide = pd.read_csv(file_path, sep=\"\\t\", decimal=\",\", encoding='latin-1')\n",
    "    rawdata = qcmd_data_wide\n",
    "    rawdata_array = rawdata.to_numpy()  # to save unmodified rawdata in hdf5 file later\n",
    "    rawdata_column_names = rawdata.columns\n",
    "\n",
    "    persistentID = os.path.basename(file_path)\n",
    "    persistentID = persistentID.replace(\"Data_\", \"\").replace(\"_rawdata.txt\", \"\")\n",
    "\n",
    "    sensors = {int(item.split(\"_\")[1].split(\" \")[0]) for item in qcmd_data_wide if item[0] == \"f\"}\n",
    "    overtones = {int(item.split(\"_\")[0][1:]) for item in qcmd_data_wide if item[0] == \"f\"}\n",
    "\n",
    "    print(\"Starting to process data with the persistent ID:\", persistentID)\n",
    "    print(\"In this dataset, the following overtones were measured:\")\n",
    "    print(overtones)\n",
    "    print(\"on the sensor positions\")\n",
    "    print(sensors)\n",
    "\n",
    "    norm_qcmd_data_wide = qcmd_data_wide\n",
    "\n",
    "    # the data contains a Time column for each of the sensors. \n",
    "    # Thus we must ensure that none of the columns labeled \"Time_n [s]\" - with n being the overtone number - is \"normalized\n",
    "    for col in qcmd_data_wide.columns: \n",
    "        if not re.match(r'Time_\\d+\\s+\\[s\\]', col): \n",
    "            norm_qcmd_data_wide[col] = qcmd_data_wide[col]-qcmd_data_wide[col].iloc[0:100].mean()\n",
    "            \n",
    "    # Next step: Create adj_qcmd_data in long format\n",
    "    adj_qcmd_data = pd.DataFrame(columns=[\"Time_s\", \"Overtone\", \"Sensor\", \"Deltaf_div_n_Hz\", \"Dissipation_ppm\"])\n",
    "\n",
    "    for sensor in sensors:\n",
    "        for overtone in overtones:\n",
    "            columns_selected = [\n",
    "                \"Time_\" + str(sensor) + \" [s]\",\n",
    "                \"f\" + str(overtone) + \"_\" + str(sensor) + \" [Hz]\",\n",
    "                \"D\" + str(overtone) + \"_\" + str(sensor) + \" [ppm]\"\n",
    "            ]\n",
    "\n",
    "            data_temp = qcmd_data_wide.loc[:, columns_selected]\n",
    "            data_temp.columns = [\"Time_s\", \"Deltaf_div_n_Hz\", \"Dissipation_ppm\"]\n",
    "            data_temp[\"Overtone\"] = float(overtone)\n",
    "            data_temp[\"Sensor\"] = float(sensor)\n",
    "\n",
    "            adj_qcmd_data = pd.concat([adj_qcmd_data, data_temp], ignore_index=True)\n",
    "\n",
    "    adj_qcmd_data[\"Deltaf_div_n_Hz\"] = adj_qcmd_data[\"Deltaf_div_n_Hz\"] / adj_qcmd_data[\"Overtone\"]\n",
    "    adj_qcmd_data[\"Deltaf_div_n_Hz\"] = adj_qcmd_data[\"Deltaf_div_n_Hz\"].astype(float)\n",
    "    adj_qcmd_data[\"Time_s\"] = adj_qcmd_data[\"Time_s\"].astype(float)\n",
    "    adj_qcmd_data[\"Dissipation_ppm\"] = adj_qcmd_data[\"Dissipation_ppm\"].astype(float)\n",
    "\n",
    "    adj_qcmd_data = adj_qcmd_data.dropna()\n",
    "\n",
    "    #print(\"Long-format data:\")\n",
    "    #display(adj_qcmd_data)\n",
    "    print(\"Transformed to normalized long format\")\n",
    "    \n",
    "    return persistentID, sensors, adj_qcmd_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b8eb66-3dcd-4244-9d52-1c35337cf696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:\n",
    "- path\n",
    "- persistenID\n",
    "- Reads in the timeline txt based on our naming conventions \n",
    "    expects title of timeline to be path+\"Data_\"+persistentID+\"_timeline.txt\"\n",
    "\n",
    "Output:\n",
    "- timeline_data_pd: adjusted time points at which liquid has been exchanged in a pandas data frame \n",
    "    column names: ['Time', 'Sensor', 'Speed' 'Information']\n",
    "\"\"\"\n",
    "\n",
    "def read_timeline_data(path, persistentID):\n",
    "    file_timeline = os.path.join(path, f\"Data_{persistentID}_timeline.txt\")\n",
    "\n",
    "    try:\n",
    "        with open(file_timeline, 'r', encoding='utf-8') as file:\n",
    "            timeline = file.read()\n",
    "            print(\"Timeline file read:\")\n",
    "            print(f\"Data_{persistentID}_timeline.txt\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file '{file_timeline}' was not found. Check if it was saved with the correct name\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Initialize lists to store timeline data\n",
    "    timelines_times = []\n",
    "    timelines_sensors = []\n",
    "    timelines_speeds = []\n",
    "    timelines_infos = []\n",
    "\n",
    "    timelines = timeline.split(\"\\n\")\n",
    "    for line in timelines:\n",
    "        line = line.strip()  # Remove leading and trailing whitespace\n",
    "\n",
    "        # Check if the line is not empty\n",
    "        if line:\n",
    "            parts = line.split(\" \", 3)\n",
    "            time_str = parts[0]\n",
    "            timelines_info = parts[3]\n",
    "\n",
    "            timelines_sensor = int(parts[1].replace(\"S\", \"\"))  # Remove 'S' prefix\n",
    "            timelines_speed = int(parts[2].replace(\"_ul-min\", \"\"))  # Remove unit of flow rate\n",
    "\n",
    "            # Split the time string into hours, minutes, and seconds\n",
    "            time_parts = time_str.split(\":\")\n",
    "\n",
    "            # If there's no hours part, assume it's zero\n",
    "            if len(time_parts) == 2:\n",
    "                hours, minutes, seconds = 0, int(time_parts[0]), int(time_parts[1])\n",
    "            elif len(time_parts) == 3:\n",
    "                hours, minutes, seconds = map(int, time_parts)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid time format: {time_str}\")\n",
    "\n",
    "            # Convert the time to seconds\n",
    "            timelines_time = hours * 3600 + minutes * 60 + seconds\n",
    "\n",
    "            timelines_times.append(timelines_time)\n",
    "            timelines_sensors.append(timelines_sensor)\n",
    "            timelines_speeds.append(timelines_speed)\n",
    "            timelines_infos.append(timelines_info)\n",
    "\n",
    "    dtype = [('Time', int), ('Sensor', int), ('Speed', int), ('Information', 'S100')]\n",
    "    timeline_column_names = ['Time', 'Sensor', 'Speed', 'Information']\n",
    "\n",
    "    timeline_data_np = np.array(list(zip(timelines_times, timelines_sensors, timelines_speeds, timelines_infos)),\n",
    "                                dtype=dtype)\n",
    "\n",
    "    adj_timeline_data_np = timeline_data_np\n",
    "    #display(adj_timeline_data_np)\n",
    "\n",
    "    # determine and exchange with real values:\n",
    "    delayS1 = 135/50\n",
    "    delayS2 = 100/50\n",
    "    delayS3 = 140/50\n",
    "    delayS4 = 135/50\n",
    "\n",
    "\n",
    "    timeline_data_np['Time'] = np.where(timeline_data_np['Sensor'] == 1,\n",
    "                                        timeline_data_np['Time'] + delayS1*timeline_data_np['Speed'],\n",
    "                                        timeline_data_np['Time'])\n",
    "    timeline_data_np['Time'] = np.where(timeline_data_np['Sensor'] == 2,\n",
    "                                        timeline_data_np['Time'] + delayS2*timeline_data_np['Speed'],\n",
    "                                        timeline_data_np['Time'])\n",
    "    timeline_data_np['Time'] = np.where(timeline_data_np['Sensor'] == 3,\n",
    "                                        timeline_data_np['Time'] + delayS3*timeline_data_np['Speed'],\n",
    "                                        timeline_data_np['Time'])\n",
    "    timeline_data_np['Time'] = np.where(timeline_data_np['Sensor'] == 4,\n",
    "                                        timeline_data_np['Time'] + delayS4*timeline_data_np['Speed'],\n",
    "                                        timeline_data_np['Time'])\n",
    "\n",
    "    dtype = ['Time', 'Sensor', 'Speed', 'Information']\n",
    "    timeline_data_pd = pd.DataFrame(timeline_data_np, columns=dtype)\n",
    "    timeline_data_pd['Information'] = timeline_data_pd['Information'].apply(lambda x: x.decode('utf-8'))\n",
    "\n",
    "    #print(\"Timeline data:\")\n",
    "    #display(timeline_data_pd)\n",
    "\n",
    "    return timeline_data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5699e025-fd1d-422c-af45-afc71d12a60f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Data_CBP_LEAF_5348222_20250530_QCMD_rawdata.txt\n",
      "Starting to process data with the persistent ID: CBP_LEAF_5348222_20250530_QCMD\n",
      "In this dataset, the following overtones were measured:\n",
      "{3, 5, 7, 9, 11, 13}\n",
      "on the sensor positions\n",
      "{1, 2, 3, 4}\n",
      "Transformed to normalized long format\n",
      "Timeline file read:\n",
      "Data_CBP_LEAF_5348222_20250530_QCMD_timeline.txt\n",
      "Data saved as:\n",
      "/Users/hboehm/Seafile/LEAF/QCMD/QCMD_data/Inbox/Data_CBP_LEAF_5348222_20250530QCMD_adj_data.csv\n",
      "/Users/hboehm/Seafile/LEAF/QCMD/QCMD_data/Inbox/Data_CBP_LEAF_5348222_20250530_S1_QCMD_adj_qcmd_data.csv\n",
      "/Users/hboehm/Seafile/LEAF/QCMD/QCMD_data/Inbox/Data_CBP_LEAF_5348222_20250530_S1_QCMD_adj_timeline.csv\n",
      "/Users/hboehm/Seafile/LEAF/QCMD/QCMD_data/Inbox/Data_CBP_LEAF_5348222_20250530_S2_QCMD_adj_qcmd_data.csv\n",
      "/Users/hboehm/Seafile/LEAF/QCMD/QCMD_data/Inbox/Data_CBP_LEAF_5348222_20250530_S2_QCMD_adj_timeline.csv\n",
      "/Users/hboehm/Seafile/LEAF/QCMD/QCMD_data/Inbox/Data_CBP_LEAF_5348222_20250530_S3_QCMD_adj_qcmd_data.csv\n",
      "/Users/hboehm/Seafile/LEAF/QCMD/QCMD_data/Inbox/Data_CBP_LEAF_5348222_20250530_S3_QCMD_adj_timeline.csv\n",
      "/Users/hboehm/Seafile/LEAF/QCMD/QCMD_data/Inbox/Data_CBP_LEAF_5348222_20250530_S4_QCMD_adj_qcmd_data.csv\n",
      "/Users/hboehm/Seafile/LEAF/QCMD/QCMD_data/Inbox/Data_CBP_LEAF_5348222_20250530_S4_QCMD_adj_timeline.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def identify_similar_files(directory):\n",
    "    files = os.listdir(directory)\n",
    "    similar_files = [file for file in files if \"rawdata.txt\" in file.lower()]\n",
    "    return similar_files\n",
    "\n",
    "def main():\n",
    "    rawdata_files = identify_similar_files(path)\n",
    "\n",
    "    if not rawdata_files:\n",
    "        print(f\"There are no files containing 'rawdata.txt' in the folder {path}\")\n",
    "        return\n",
    "    \n",
    "    for i, file in enumerate(rawdata_files, start=1):\n",
    "        print(f\"{i}: {file}\")\n",
    "        file_path = os.path.join(path, file)\n",
    "\n",
    "        persistentID, sensors, adj_qcmd_data = process_rawdata(file_path)\n",
    "        \n",
    "        if not persistentID:\n",
    "            print(\"Error processing rawdata. Exiting.\")\n",
    "            return\n",
    "\n",
    "        # Read timeline data using persistentID and path\n",
    "        timeline_data = read_timeline_data(path, persistentID)\n",
    "\n",
    "        if timeline_data is None:\n",
    "            print(\"Error reading timeline data. Exiting.\")\n",
    "            return\n",
    "\n",
    "        # Save sensor-specific adj_qcmd_data and adjusted timeline\n",
    "        print(\"Data saved as:\")\n",
    "        \n",
    "        baseID = persistentID.replace(\"_QCMD\", \"\")\n",
    "        csv_filename = os.path.join(path, \"Data_\" + baseID)\n",
    "        adj_qcmd_data.to_csv(csv_filename + \"_QCMD_adj_data.csv\", index=True)\n",
    "        print(csv_filename + \"QCMD_adj_data.csv\")\n",
    "\n",
    "        # Loop through the sensors\n",
    "        for sensor in sensors:\n",
    "            # Save sensor-specific adjusted QCM-D data as a CSV file\n",
    "            sensor_qcmd_data = adj_qcmd_data[adj_qcmd_data[\"Sensor\"] == sensor].copy()\n",
    "            del sensor_qcmd_data[\"Sensor\"]\n",
    "            adj_qcmd_data_name = f\"{csv_filename}_S{sensor}_QCMD_adj_qcmd_data.csv\"\n",
    "            sensor_qcmd_data.to_csv(adj_qcmd_data_name, index=True)\n",
    "            print(adj_qcmd_data_name)\n",
    "\n",
    "            # Save sensor-specific adjusted timeline as a CSV file\n",
    "            adj_timeline_filename = f\"{csv_filename}_S{sensor}_QCMD_adj_timeline.csv\"\n",
    "            adj_sensor_timeline = timeline_data[timeline_data[\"Sensor\"] == sensor].copy()\n",
    "            del adj_sensor_timeline[\"Sensor\"]\n",
    "            adj_sensor_timeline.to_csv(adj_timeline_filename, index=True)\n",
    "            print(adj_timeline_filename)\n",
    "\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a342e-5c3b-4b30-b5ae-0809128462d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b857384b-581c-4f84-bc58-dea536bd009d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
